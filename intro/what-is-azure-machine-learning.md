# What is Azure Machine Learning?

Before we delve into the components of Azure Machine Learning service and its tools, let us first describe the landscape of artificial intelligence, what it means to you as a data scientist, data engineer, or developer, and then how Azure ML fits into the landscape and addresses your needs.

## What Artificial Intelligence/Machine Learning/Deep Learning mean to the data scientist, data engineer, and developer

Artificial Intelligence (AI) is a term that has been around since the 1950s to describe a set of processes that enable computers to think more like humans and to learn on their own. Computers have long been used to solve problems, but the field of AI aims to have machines use information from the past and use that data to inform future decisions. Machine learning is one example of a form of artificial intelligence that falls underneath the broader umbrella term of "AI".

In this article, we will focus on one of AI's most important disciplines: **machine learning (ML)** and its unique subdisciplines: supervised learning, unsupervised learning, reinforcement learning, deep learning (DL), and transfer learning. As machine learning becomes critical to the success of organizations, data scientists, data engineers, and developers are expected to expand their knowledge to meet these needs and achieve the requirements for digital transformation. AI becomes critical to an organization when the capabilities the technology provides is either at the core of that organization's business or enables the organization to innovate and gain a competitive edge in the marketplace. Let us continue by defining the primary fields of machine learning and deep learning.

### Machine learning

Machine learning is a data science technique used to extract predictions or patterns from statistical models by allowing computers to use existing data to forecast future outcomes, behaviors, and trends. This method of learning is accomplished without explicitly programming routines for computers to follow. There are too many variables to reliably account for every potential data point, logic flow, and decision to effectively program an application that is flexible enough to work with any given problem set and knowledge domain. Machine learning overcomes the terse and rigid constraints of explicitly programmed instructions by using special algorithms to find patterns and insights in a wide range of data. Machine learning systems harness this flexibility to use data from sources such as apps, sensors, historical data, networks, and devices to build its own logic to solve a problem or extract insight.

There are several approaches to machine learning that focus on different sets of problems. Some of the most widely used approaches are:

#### Supervised learning

Supervised learning means that you have access to data where the outcomes are already known. You use this labeled data to teach the algorithm what conclusions to arrive to when you train your model. This means that the data should have target values that describe the prediction, such as whether a flight was delayed or information defined that are essential data points that can be used to make that prediction. In the case of predicting flight delays, this could include the origin and destination airports, date, airline, weather conditions, and whether the flight was delayed. You are responsible for selecting these data points, otherwise known as features, choosing a suitable algorithm, using a portion of the historical data for training the model, and a portion to test the model with data it has not yet seen. The trained algorithm, or model, can then be used to make predictions on new data that contain the same features.

Refer to the [Azure Machine Learning Algorithm Cheat Sheet](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet) to view a list of some of algorithms you can use to conduct supervised learning. All of the algorithms listed on the sheet, except for K-means clustering, are used in supervised learning, with the regression and classification categories of algorithms used most often.

#### Unsupervised learning

The majority of data generated in the world today is unlabeled. Labeling data for training a machine learning model can be very costly, and even the best-curated data sets have only thousands of labels. Since these labels are crucial to supervised learning, an initial investment must be made to apply them. When you have data that is neither classified nor labeled, you could use an unsupervised algorithm to act on the information without guidance. One goal of the algorithm is to group data samples according to patterns in similarities and distances among them. This could mean grouping the data into clusters, as K-means does, or finding different ways of looking at complex data so that it appears more uncomplicated than in its unstructured form. Unlike supervised learning, you do not provide any prior teaching, which leaves the machine to find the hidden structure in unlabeled data by itself.

One example of unsupervised learning is used in healthcare. Analysts detect causality and identify correlations humans may miss by [inputting health data like blood pressure, heart rate, weight, and prescription data](http://people.csail.mit.edu/dsontag/courses/mlhc_summer18/day2/causal_inference.pdf) into an unsupervised learning algorithm.

Other applications for unsupervised learning include:

- _Data drift_: You initially train your machine learning models on data whose characteristics may change over time. This drift can lead to lower-quality predictions over time. One way to address this problem is to create probability distributions using unsupervised learning to assess how different new data is from the training data. If there is a significant difference, then the model should be retrained with current data.
- _Outliers_: Use unsupervised learning to detect outliers within a data set. This detection can lead to improved training by ignoring or removing outliers and addressing them separately, as well as other applications such as anomaly detection.
- _Overfitting_: One of the challenges of training a machine learning algorithm is overfitting to the training data, leading to poor performance on data it has never seen. This is oftentimes caused by extracting too much from noise in the training data and missing the signal, or essence, of the information. In these cases, unsupervised learning can be used as a _regulator_ to reduce the complexity of the machine learning algorithm by removing excess noise from the training data. This unsupervised pretraining transforms the original data, and this generated data is fed into the supervised learning algorithm. The algorithm has less noise to contend with, allowing it to capture more of the signal and improve its generalization error.

When deciding between supervised and unsupervised learning algorithms, the general rule is to use supervised learning when you have narrowly-defined tasks for which you have distinct patterns that do not change much over time. The datasets you use in this case should be sufficiently large and have well-defined labels. However, if the problem you are trying to solve has patterns that are continually changing or unknown, and you do not have large, labeled datasets, unsupervised learning will give you the best outcome.

#### Reinforcement learning

Reinforcement learning takes a more organic, almost human approach to learning. This class of algorithms interacts with a simulated or real environment to explore different strategies that result in a maximum reward. The choices are reinforced by either a favorable or unfavorable outcome in the form of a reward signal, sometimes called a _reinforcement signal_. Each choice the algorithm, or agent, makes when it encounters a new data point is impacted by how great the reward was in its last decision. If the action led to lower performance compared to an agent that acts optimally, this leads to the notion of regret. In effect, the algorithm continually modifies its strategy with the driving goal to achieve the highest long-term reward.

An optimal reinforcement learning algorithm addresses the explore vs. exploit tradeoff when making decisions each step of the way. It will explore low-value options, even if selecting one of these options leads to a low short-term reward so that it can gain a higher long-term reward. This is because the optimized agent reasons about the long-term consequences of its actions when making a decision. Instead of choosing to explore low-value options, the algorithm might choose to exploit the knowledge it has gained to maximize the reward, given its current learnings.

Reinforcement learning is highly prevalent in robotics, where the set of sensor readings at one point in time is a data point the algorithm uses to choose the robot's next action. Other examples include learning how to master chess or how to drive a vehicle without crashing into obstacles. Sometimes the reinforcement comes from user interaction. For instance, reinforcement learning can be used in product recommendations where shoppers have the chance to say in the user interface to either "show more like this" or "do not show me any more products like this".

### Deep learning

One of the most successful classes of machine learning algorithms in recent years is the neural network, or deep neural network (DNN). These algorithms encompass the deep learning subdiscipline of machine learning, as it uses what is called a neural network architecture that was originally inspired by how a brain works, rather than using traditional statistical frameworks. This architecture contains several stacked layers on top of each other, with higher levels of abstraction occurring within each layer. This layering is where the term "deep" comes from. The more layers that you use, the deeper the neural network architecture, and the more abstract interpretations of data can be made. This approach is especially useful when working with data without structured attributes or features, leaving it up to the algorithm to come up with its own interpretation of what the input represents. In comparison to most conventional machine learning techniques, deep learning requires massive amounts of compute power, more training time, and enormous datasets. Deep learning techniques have been around for many years, but only because of recent breakthroughs in the size of available datasets and computational resources has it become possible to apply them to hard, real-world problems.

Some applications of deep learning include speech recognition, image and object recognition, and Natural Language Processing (NLP). These capabilities are achieved through the use of neural network architectures, such as convolutional, recurrent neural networks, and multilayer perceptron.

#### Transfer learning

Transfer learning is a deep learning process that allows you to reuse a model that has already been pre-trained to solve a similar problem, potentially saving you significant time and resources. This is done by retraining all or some of the layers of the existing model so that it solves your new problem.

To give you an example of how transfer learning works, imagine that you have a requirement to train a new image classifier to recognize a handful of categories, such as bicycles, tennis shoes, and skateboards. You could either train a new model from scratch or start with an existing model that has already been trained to recognize large classes of images. One such pre-trained model exists that you can use in this example. It is a [deep convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) model, named [Inception](https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip), that was trained to recognize and classify images to identify thousands of objects like surfboards, pizza, and giraffes. Because of the type of algorithm used and the amount of training conducted to build this model, the lower image feature layers recognize simple features of the images, such as edges, and the higher layers can recognize complex features, such as shapes. When you use this existing model that is pre-trained with thousands of images as a starting point, as in this example, and retrain just the final layer of the model, this is called transfer learning. You have cut out extensive training time by using a much smaller image set to teach your new model to recognize a narrow set of categories. In effect, you transferred the Inception model's ability to classify a wide range of images to the narrow set of categories of your new image classifier. This way, you can drastically reduce the time and resources used to train the new model because you do not need to train all of the layers of the neural net.

## The Microsoft AI and ML spectrum

Microsoft is a leader in AI and in providing the tools and services needed to help organizations of all sizes benefit from the capabilities it provides. Microsoft CEO, Satya Nadella, summarizes Microsoft's vision for AI:

> "It's not enough just to sort of have AI capability that we can exercise—you also need the **ability to democratize it** so that **every business can truly benefit from it**... That to me is our identity around AI."
> _– [Satya Nadella](https://www.forbes.com/sites/bobevans1/2018/06/04/microsoft-ceo-satya-nadella-on-the-extraordinary-potential-of-ai/#986818e162ff)_

Microsoft provides a vast number of technologies that you, as a developer, data scientist, or data engineer, can use to harness the power of AI and machine learning (ML). The number of options can be overwhelming if you are not a seasoned AI expert and Azure professional, and know which services to use when so many tend to have capabilities that overlap. A few of these options are Azure Machine Learning, Cognitive Services, Azure Databricks, HDInsight, SQL Server, ML.NET, Azure Batch, and Power BI.

You can view these offerings from a very high level in the context of a spectrum of AI and ML choices. This spectrum begins with pre-built and easily accessible models that require no training or data science expertise, provided by Microsoft, and ends with entirely custom models trained, evaluated, and deployed by developers, sysadmins, data engineers, or data scientists.

The following diagram helps visualize the spectrum of choices:

![This diagram shows a spectrum of Microsoft AI and ML offerings, from pre-built to custom models.](media/ai-spectrum.png 'Microsoft AI and ML spectrum')

The left side of this spectrum, which includes the pre-built models, is provided by [Azure Cognitive Services](https://azure.microsoft.com/en-us/services/cognitive-services/). Cognitive Services also covers the middle of the spectrum, which still uses pre-built models, but they are customizable with your own data, enabling you to train the model without needing to program or host the model in your own environment. Currently, this level of customization can be enabled by the Vision and Speech APIs. The middle of the spectrum also is where you can use pre-built models with transfer learning to customize them for your needs. This left to middle range of the spectrum may be sufficient for your business needs, and you can easily consume them through simple REST calls from your applications. The pre-trained machine learning models are built, maintained, and trained by Microsoft to cover a broad range of scenarios. However, you might encounter a situation where your challenges are too specific to effectively use the models Cognitive Services provides, even the customizable ones. When this happens, you need to set up an environment where you can write custom code, access your data, and use 3rd-party libraries to solve your problem. There are a plethora of libraries you can use to aid your development, and a large number of pre-built models you can use to simplify the code you need to write. However, sometimes, even these options are not sufficient for your problem. When this happens, you need to explore your options on the right-hand side of the spectrum to create custom models tailored to your scenario and your data. It is on this side of the spectrum where you write most of the code needed to solve your problem.

**This right-hand side of the spectrum is where [Azure Machine Learning service](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml) comes to play.**

## How the Azure Machine Learning service fits in the picture and addresses your needs

[Azure Machine Learning service](/azure/machine-learning/service/overview-what-is-azure-ml) is a fully managed cloud service used to train, deploy, and manage machine learning models at scale. Given the variety of services within Azure that you can choose from to create AI solutions, Azure Machine Learning service is the one platform in Azure that "glues" together the entire custom AI/ML development story. When you couple the rich set of tools with the service, you have everything you need to get started with experimenting and creating AI solutions on the right-hand side of the AI spectrum.

Azure Machine Learning service fully supports open-source technologies so that you can use tens of thousands of open-source Python packages such as TensorFlow, PyTorch, MXNet, and scikit-learn. All you need is a Python-enabled environment to get started with setting up and using Azure Machine Learning service through its [Python SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py). Powerful tools are also available, such as [notebook VMs](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment#notebookvm), [Azure notebooks](https://notebooks.azure.com/), [Jupyter notebooks](http://jupyter.org), or the [Azure Machine Learning for Visual Studio Code](https://aka.ms/vscodetoolsforai) extension to make it easy to explore and transform data, and then train and deploy models. Azure Machine Learning service includes features that automate model generation and tuning with ease, efficiency, and accuracy.

Use Azure Machine Learning service to train, deploy, and manage machine learning models using Python and CLI at cloud scale. For a low-code or no-code option, use the interactive, [visual interface](https://docs.microsoft.com/en-us/azure/machine-learning/service/ui-quickstart-run-experiment) to easily and quickly build, test, and deploy models using pre-built machine learning algorithms.

![Azure Machine Learning helps you prepare your data, build and register your models, then quickly deploy them.](media/steps-to-using-azureml.png 'Steps to using Azure ML')

As shown in the diagram above, Azure Machine Learning service helps you perform each step of the data science process. These steps include:

- **Data preparation**: Prepare your data for model training, using notebooks that can run on [compute resources](./tools.md) ([Azure Machine Learning Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute), Azure Databricks, VMs, etc.) to explore and prepare your data quickly and cost-effectively by autoscaling using CPUs and GPUs. Get started with a [tutorial that uses the data prep package from the Azure Machine Learning SDK](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-data-prep).
- **Experimentation**: Use notebook VMs, Azure notebooks, Jupyter notebooks, or Visual Studio Code with the Azure Machine Learning extension to explore your data, transform it, and train and test your ML models. You can start training on your local machine and then scale out to the cloud, using one of the compute resources listed above. Also, the automated machine learning feature can improve productivity by using automatic model selection and hyperparameter tuning to accelerate the model training process. With automated machine learning, it's possible to evaluate the importance of model features and measure the relationships between those features and a model's outputs automatically. This allows a data scientist to identify potential areas of improvement more quickly.
- **Model management**: Use the Azure Machine Learning SDK to register your trained models in your workspace. If you have a model that you store in multiple files, you can register it as a single model as well. Model registration allows you to store and version your models, helping you organize and keep track of your trained models. Azure Machine Learning uses the [Machine Learning Operations (MLOps) approach](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-model-management-and-deployment), which improves the quality and consistency of your ML solutions.
- **Deployment**: The Azure Machine Learning SDK makes it easy to package your trained models in Docker containers and deploy them to [AML Compute](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute), [Azure Kubernetes Service](https://docs.microsoft.com/en-us/azure/aks/intro-kubernetes) (AKS), [Azure Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/container-instances-overview) (ACI), and [IoT Edge](https://docs.microsoft.com/en-us/azure/iot-edge/about-iot-edge).

Data scientists can use Azure Machine Learning service to build their custom machine learning and deep learning models, then register them to run and track experiments that are associated with each version of the model as they continue to refine and retrain their models. The deployment options provided by Azure ML help them deploy new versions of their models without needing to take down existing services hosting their models, disrupting current users and applications.

Developers and data engineers benefit from improved productivity with autoscaling compute and DevOps for machine learning. The Azure Machine Learning SDK makes it easy to script one-click deployments to the cloud and the edge, and use DevOps tools to automate that process if desired. Data engineers can harness the power of Apache Spark from Azure notebooks and Jupyter notebooks to perform data exploration and preparation at scale. All of these capabilities are accessible from your favorite Python environment using the latest open-source frameworks, such as TensorFlow, PyTorch, scikit-learn, and MXNet.

## Next steps

- [Configure your development environment](./environment-setup.md)
- [Tools for data engineering, data science, and AI](./tools.md)

Read next: [Overview of Azure Machine Learning service architecture and concepts](./architecture-overview.md)
